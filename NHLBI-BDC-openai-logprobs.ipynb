{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NHLBI: BioData Catalyst OpenAI Tutorial\n",
    "## Using logprobs for classification and Q&A evaluation\n",
    "**Authors**: Andrew Blair, James Hills, Shyamal Anadkats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates the use of the `logprobs` parameter in the Chat Completions API. When `logprobs` is enabled, the API returns the log probabilities of each output token, along with a limited number of the most likely tokens at each token position and their log probabilities. The relevant request parameters are:\n",
    "* `logprobs`: Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the content of message. This option is currently not available on the `gpt-4-vision-preview` model.\n",
    "* `top_logprobs`: An integer between 0 and 5 specifying the number of most likely tokens to return at each token position, each with an associated log probability. `logprobs` must be set to true if this parameter is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log probabilities of output tokens indicate the likelihood of each token occurring in the sequence given the context. To simplify, a logprob is `log(p)`, where `p` = probability of a token occurring at a specific position based on the previous tokens in the context. Some key points about `logprobs`:\n",
    "* Higher log probabilities suggest a higher likelihood of the token in that context. This allows users to gauge the model's confidence in its output or explore alternative responses the model considered.\n",
    "* Logprob can be any negative number or `0.0`. `0.0` corresponds to 100% probability.\n",
    "* Logprobs allow us to compute the joint probability of a sequence as the sum of the logprobs of the individual tokens. This is useful for scoring and ranking model outputs. Another common approach is to take the average per-token logprob of a sentence to choose the best generation.\n",
    "* We can examine the `logprobs` assigned to different candidate tokens to understand what options the model considered plausible or implausible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "While there are a wide array of use cases for `logprobs`, this notebook will focus on its use for:\n",
    "\n",
    "1. Classification tasks\n",
    "\n",
    "* Large Language Models excel at many classification tasks, but accurately measuring the model's confidence in its outputs can be challenging. `logprobs` provide a probability associated with each class prediction, enabling users to set their own classification or confidence thresholds.\n",
    "  \n",
    "* Demonstrate how to develop a classification prompt and use the `logprobs` to assess the confidence for classifying cardiac research abstracts into four categories: **Congenital Heart Disease, Cardiometabolic, Atrial Fibrillation, and Congestive Heart Failure**\n",
    "\n",
    "\n",
    "2. Retrieval (Q&A) evaluation\n",
    "\n",
    "* `logprobs` can assist with self-evaluation in retrieval applications. In the Q&A example, the model outputs a contrived `has_sufficient_context_for_answer` boolean, which can serve as a confidence score of whether the answer is contained in the retrieved content. Evaluations of this type can reduce retrieval-based hallucinations and enhance accuracy.\n",
    "\n",
    "3. Autocomplete\n",
    "*  `logprobs` could help us decide how to suggest words as a user is typing.\n",
    "\n",
    "4. Token highlighting and outputting bytes\\n\",\n",
    "*  Users can easily create a token highlighter using the built in tokenization that comes with enabling `logprobs`. Additionally, the bytes parameter includes the ASCII encoding of each output character, which is particularly useful for reproducing emojis and special characters.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports and utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from math import exp\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(\n",
    "    messages: list[dict[str, str]],\n",
    "    model: str = \"gpt-4\",\n",
    "    max_tokens=500,\n",
    "    temperature=0,\n",
    "    stop=None,\n",
    "    seed=123,\n",
    "    tools=None,\n",
    "    logprobs=None,  # whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the content of message..\n",
    "    top_logprobs=None,\n",
    ") -> str:\n",
    "    params = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": temperature,\n",
    "        \"stop\": stop,\n",
    "        \"seed\": seed,\n",
    "        \"logprobs\": logprobs,\n",
    "        \"top_logprobs\": top_logprobs,\n",
    "    }\n",
    "    if tools:\n",
    "        params[\"tools\"] = tools\n",
    "\n",
    "    completion = client.chat.completions.create(**params)\n",
    "    return completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Using `logprobs` to assess confidence for classification tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we want to create a system to classify research article abstracts into a set of pre-defined categories. Without `logprobs`, we can use Chat Completion to do this, but it much more difficult to assess the certainy with which the model made its classifications.\n",
    "\n",
    "Now, with `logprobs` enabled, we can see exactly how confident the model is in its predictions, which is crucial for creating an accurate and trustworthy classifier. For example, if the log probability for the chosen category is high, this suggests the model is quite confident in its classification. If it's low, this suggests the model is less confident. This can be particularly useful in cases where the model's classification is not what you expected, or when the model's output needs to be reviewed or validated by a human."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll begin with a prompt that presents the model with four categories: **Congenital Heart Disease, Cardiometabolic, Atrial Fibrillation, and Congestive Heart Failure**. The model is then tasked with classifying articles into these categories based solely on their abstracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFICATION_PROMPT = \"\"\"You will be given an abstract of a research article.\n",
    "Classify the article into one of the following categories: Congenital Heart Disease, Cardiometabolic Disorder, Atrial Fibrillation, and Congestive Heart Failure.\n",
    "Return only the name of one of the four categories, and nothing else.\n",
    "MAKE SURE your output is one of the four categories stated.\n",
    "Article Abstract: {headline}\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at three sample headlines, and first begin with a standard Chat Completions output, without `logprobs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = [\n",
    "    \n",
    "    # Congenital Heart Disease\n",
    "    # Richter, F., Morton, S.U., Kim, S.W. et al. Genomic analyses implicate noncoding de novo variants in congenital heart disease. Nat Genet 52, 769–777 (2020). \n",
    "    \"A genetic etiology is identified for one-third of patients with congenital heart disease (CHD), with 8% of cases attributable to coding de novo variants (DNVs). To assess the contribution of noncoding DNVs to CHD, we compared genome sequences from 749 CHD probands and their parents with those from 1,611 unaffected trios. Neural network prediction of noncoding DNV transcriptional impact identified a burden of DNVs in individuals with CHD (n = 2,238 DNVs) compared to controls (n = 4,177; P = 8.7 × 10−4). Independent analyses of enhancers showed an excess of DNVs in associated genes (27 genes versus 3.7 expected, P = 1 × 10−5). We observed significant overlap between these transcription-based approaches (odds ratio (OR) = 2.5, 95% confidence interval (CI) 1.1–5.0, P = 5.4 × 10−3). CHD DNVs altered transcription levels in 5 of 31 enhancers assayed. Finally, we observed a DNV burden in RNA-binding-protein regulatory sites (OR = 1.13, 95% CI 1.1–1.2, P = 8.8 × 10−5). Our findings demonstrate an enrichment of potentially disruptive regulatory noncoding DNVs in a fraction of CHD at least as high as that observed for damaging coding DNVs.\",\n",
    "    \n",
    "    # Cardiometabolic\n",
    "    # Laber, S. et al. Discovering cellular programs of intrinsic and extrinsic drivers of metabolic traits using LipocyteProfiler. Cell Genom. 3, 100346 (2023).\n",
    "    \"A primary obstacle in translating genetic associations with disease into therapeutic strategies is elucidating the cellular programs affected by genetic risk variants and effector genes. Here, we introduce LipocyteProfiler, a cardiometabolic-disease-oriented high-content image-based profiling tool that enables evaluation of thousands of morphological and cellular profiles that can be systematically linked to genes and genetic variants relevant to cardiometabolic disease. We show that LipocyteProfiler allows surveillance of diverse cellular programs by generating rich context- and process-specific cellular profiles across hepatocyte and adipocyte cell-state transitions. We use LipocyteProfiler to identify known and novel cellular mechanisms altered by polygenic risk of metabolic disease, including insulin resistance, fat distribution, and the polygenic contribution to lipodystrophy. LipocyteProfiler paves the way for large-scale forward and reverse deep phenotypic profiling in lipocytes and provides a framework for the unbiased identification of causal relationships between genetic variants and cellular programs relevant to human disease.\",\n",
    "    \n",
    "    # Atrial Fibrillation\n",
    "    # Miyazawa, K. et al. Cross-ancestry genome-wide analysis of atrial fibrillation unveils disease biology and enables cardioembolic risk prediction. Nat. Genet. 55, 187–197 (2023).\n",
    "    \"Atrial fibrillation (AF) is a common cardiac arrhythmia resulting in increased risk of stroke. Despite highly heritable etiology, our understanding of the genetic architecture of AF remains incomplete. Here we performed a genome-wide association study in the Japanese population comprising 9,826 cases among 150,272 individuals and identified East Asian-specific rare variants associated with AF. A cross-ancestry meta-analysis of >1 million individuals, including 77,690 cases, identified 35 new susceptibility loci. Transcriptome-wide association analysis identified IL6R as a putative causal gene, suggesting the involvement of immune responses. Integrative analysis with ChIP-seq data and functional assessment using human induced pluripotent stem cell-derived cardiomyocytes demonstrated ERRg as having a key role in the transcriptional regulation of AF-associated genes. A polygenic risk score derived from the cross-ancestry meta-analysis predicted increased risks of cardiovascular and stroke mortalities and segregated individuals with cardioembolic stroke in undiagnosed AF patients. Our results provide new biological and clinical insights into AF genetics and suggest their potential for clinical applications.\",\n",
    "    \n",
    "    # Congestive Heart Failure\n",
    "    # Joseph, J. et al. Genetic architecture of heart failure with preserved versus reduced ejection fraction. Nat. Commun. 13, 7753 (2022).\n",
    "    \"Pharmacologic clinical trials for heart failure with preserved ejection fraction have been largely unsuccessful as compared to those for heart failure with reduced ejection fraction. Whether differences in the genetic underpinnings of these major heart failure subtypes may provide insights into the disparate outcomes of clinical trials remains unknown. We utilize a large, uniformly phenotyped, single cohort of heart failure sub-classified into heart failure with reduced and with preserved ejection fractions based on current clinical definitions, to conduct detailed genetic analyses of the two heart failure sub-types. We find different genetic architectures and distinct genetic association profiles between heart failure with reduced and with preserved ejection fraction suggesting differences in underlying pathobiology. The modest genetic discovery for heart failure with preserved ejection fraction (one locus) compared to heart failure with reduced ejection fraction (13 loci) despite comparable sample sizes indicates that clinically defined heart failure with preserved ejection fraction likely represents the amalgamation of several, distinct pathobiological entities. Development of consensus sub-phenotyping of heart failure with preserved ejection fraction is paramount to better dissect the underlying genetic signals and contributors to this highly prevalent condition.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You will be given an abstract of a research article.\n",
      "Classify the article into one of the following categories: Congenital Heart Disease, Cardiometabolic Disorder, Atrial Fibrillation, and Congestive Heart Failure.\n",
      "Return only the name of one of the four categories, and nothing else.\n",
      "MAKE SURE your output is one of the four categories stated.\n",
      "Article Abstract: A genetic etiology is identified for one-third of patients with congenital heart disease (CHD), with 8% of cases attributable to coding de novo variants (DNVs). To assess the contribution of noncoding DNVs to CHD, we compared genome sequences from 749 CHD probands and their parents with those from 1,611 unaffected trios. Neural network prediction of noncoding DNV transcriptional impact identified a burden of DNVs in individuals with CHD (n = 2,238 DNVs) compared to controls (n = 4,177; P = 8.7 × 10−4). Independent analyses of enhancers showed an excess of DNVs in associated genes (27 genes versus 3.7 expected, P = 1 × 10−5). We observed significant overlap between these transcription-based approaches (odds ratio (OR) = 2.5, 95% confidence interval (CI) 1.1–5.0, P = 5.4 × 10−3). CHD DNVs altered transcription levels in 5 of 31 enhancers assayed. Finally, we observed a DNV burden in RNA-binding-protein regulatory sites (OR = 1.13, 95% CI 1.1–1.2, P = 8.8 × 10−5). Our findings demonstrate an enrichment of potentially disruptive regulatory noncoding DNVs in a fraction of CHD at least as high as that observed for damaging coding DNVs.\n",
      "Category: Congenital Heart Disease\n",
      "\n",
      "You will be given an abstract of a research article.\n",
      "Classify the article into one of the following categories: Congenital Heart Disease, Cardiometabolic Disorder, Atrial Fibrillation, and Congestive Heart Failure.\n",
      "Return only the name of one of the four categories, and nothing else.\n",
      "MAKE SURE your output is one of the four categories stated.\n",
      "Article Abstract: A primary obstacle in translating genetic associations with disease into therapeutic strategies is elucidating the cellular programs affected by genetic risk variants and effector genes. Here, we introduce LipocyteProfiler, a cardiometabolic-disease-oriented high-content image-based profiling tool that enables evaluation of thousands of morphological and cellular profiles that can be systematically linked to genes and genetic variants relevant to cardiometabolic disease. We show that LipocyteProfiler allows surveillance of diverse cellular programs by generating rich context- and process-specific cellular profiles across hepatocyte and adipocyte cell-state transitions. We use LipocyteProfiler to identify known and novel cellular mechanisms altered by polygenic risk of metabolic disease, including insulin resistance, fat distribution, and the polygenic contribution to lipodystrophy. LipocyteProfiler paves the way for large-scale forward and reverse deep phenotypic profiling in lipocytes and provides a framework for the unbiased identification of causal relationships between genetic variants and cellular programs relevant to human disease.\n",
      "Category: Cardiometabolic Disorder\n",
      "\n",
      "You will be given an abstract of a research article.\n",
      "Classify the article into one of the following categories: Congenital Heart Disease, Cardiometabolic Disorder, Atrial Fibrillation, and Congestive Heart Failure.\n",
      "Return only the name of one of the four categories, and nothing else.\n",
      "MAKE SURE your output is one of the four categories stated.\n",
      "Article Abstract: Atrial fibrillation (AF) is a common cardiac arrhythmia resulting in increased risk of stroke. Despite highly heritable etiology, our understanding of the genetic architecture of AF remains incomplete. Here we performed a genome-wide association study in the Japanese population comprising 9,826 cases among 150,272 individuals and identified East Asian-specific rare variants associated with AF. A cross-ancestry meta-analysis of >1 million individuals, including 77,690 cases, identified 35 new susceptibility loci. Transcriptome-wide association analysis identified IL6R as a putative causal gene, suggesting the involvement of immune responses. Integrative analysis with ChIP-seq data and functional assessment using human induced pluripotent stem cell-derived cardiomyocytes demonstrated ERRg as having a key role in the transcriptional regulation of AF-associated genes. A polygenic risk score derived from the cross-ancestry meta-analysis predicted increased risks of cardiovascular and stroke mortalities and segregated individuals with cardioembolic stroke in undiagnosed AF patients. Our results provide new biological and clinical insights into AF genetics and suggest their potential for clinical applications.\n",
      "Category: Atrial Fibrillation\n",
      "\n",
      "You will be given an abstract of a research article.\n",
      "Classify the article into one of the following categories: Congenital Heart Disease, Cardiometabolic Disorder, Atrial Fibrillation, and Congestive Heart Failure.\n",
      "Return only the name of one of the four categories, and nothing else.\n",
      "MAKE SURE your output is one of the four categories stated.\n",
      "Article Abstract: Pharmacologic clinical trials for heart failure with preserved ejection fraction have been largely unsuccessful as compared to those for heart failure with reduced ejection fraction. Whether differences in the genetic underpinnings of these major heart failure subtypes may provide insights into the disparate outcomes of clinical trials remains unknown. We utilize a large, uniformly phenotyped, single cohort of heart failure sub-classified into heart failure with reduced and with preserved ejection fractions based on current clinical definitions, to conduct detailed genetic analyses of the two heart failure sub-types. We find different genetic architectures and distinct genetic association profiles between heart failure with reduced and with preserved ejection fraction suggesting differences in underlying pathobiology. The modest genetic discovery for heart failure with preserved ejection fraction (one locus) compared to heart failure with reduced ejection fraction (13 loci) despite comparable sample sizes indicates that clinically defined heart failure with preserved ejection fraction likely represents the amalgamation of several, distinct pathobiological entities. Development of consensus sub-phenotyping of heart failure with preserved ejection fraction is paramount to better dissect the underlying genetic signals and contributors to this highly prevalent condition.\n",
      "Category: Congestive Heart Failure\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for article in abstracts:\n",
    "    print(CLASSIFICATION_PROMPT.format(headline=article))\n",
    "    API_RESPONSE = client.chat.completions.create(model=\"gpt-3.5-turbo\", \n",
    "                                   messages=[{\"role\": \"user\", \"content\": CLASSIFICATION_PROMPT.format(headline=article)}],\n",
    "\n",
    "    )\n",
    "    print(f\"Category: {API_RESPONSE.choices[0].message.content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the selected category for each headline. However, we have no visibility into the confidence of the model in its predictions. Let's rerun the same prompt but with `logprobs` enabled, and `top_logprobs` set to 2 (this will show us the 2 most likely output tokens for each token). Additionally we can also output the linear probability of each output token, in order to convert the log probability to the more easily interprable scale of 0-100%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article Abstract: A genetic etiology is identified for one-third of patients with congenital heart disease (CHD), with 8% of cases attributable to coding de novo variants (DNVs). To assess the contribution of noncoding DNVs to CHD, we compared genome sequences from 749 CHD probands and their parents with those from 1,611 unaffected trios. Neural network prediction of noncoding DNV transcriptional impact identified a burden of DNVs in individuals with CHD (n = 2,238 DNVs) compared to controls (n = 4,177; P = 8.7 × 10−4). Independent analyses of enhancers showed an excess of DNVs in associated genes (27 genes versus 3.7 expected, P = 1 × 10−5). We observed significant overlap between these transcription-based approaches (odds ratio (OR) = 2.5, 95% confidence interval (CI) 1.1–5.0, P = 5.4 × 10−3). CHD DNVs altered transcription levels in 5 of 31 enhancers assayed. Finally, we observed a DNV burden in RNA-binding-protein regulatory sites (OR = 1.13, 95% CI 1.1–1.2, P = 8.8 × 10−5). Our findings demonstrate an enrichment of potentially disruptive regulatory noncoding DNVs in a fraction of CHD at least as high as that observed for damaging coding DNVs.\n",
      "\n",
      "Category: Congenital Heart Disease\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style='color: cyan'>Output token 1:</span> Cong, <span style='color: darkorange'>logprobs:</span> -8.418666e-06, <span style='color: magenta'>linear probability:</span> 100.0%<br><span style='color: cyan'>Output token 2:</span> The, <span style='color: darkorange'>logprobs:</span> -13.094096, <span style='color: magenta'>linear probability:</span> 0.0%<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Article Abstract: A primary obstacle in translating genetic associations with disease into therapeutic strategies is elucidating the cellular programs affected by genetic risk variants and effector genes. Here, we introduce LipocyteProfiler, a cardiometabolic-disease-oriented high-content image-based profiling tool that enables evaluation of thousands of morphological and cellular profiles that can be systematically linked to genes and genetic variants relevant to cardiometabolic disease. We show that LipocyteProfiler allows surveillance of diverse cellular programs by generating rich context- and process-specific cellular profiles across hepatocyte and adipocyte cell-state transitions. We use LipocyteProfiler to identify known and novel cellular mechanisms altered by polygenic risk of metabolic disease, including insulin resistance, fat distribution, and the polygenic contribution to lipodystrophy. LipocyteProfiler paves the way for large-scale forward and reverse deep phenotypic profiling in lipocytes and provides a framework for the unbiased identification of causal relationships between genetic variants and cellular programs relevant to human disease.\n",
      "\n",
      "Category: Cardiometabolic Disorder\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style='color: cyan'>Output token 1:</span> Card, <span style='color: darkorange'>logprobs:</span> -0.0026939593, <span style='color: magenta'>linear probability:</span> 99.73%<br><span style='color: cyan'>Output token 2:</span> Cong, <span style='color: darkorange'>logprobs:</span> -5.9219046, <span style='color: magenta'>linear probability:</span> 0.27%<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Article Abstract: Atrial fibrillation (AF) is a common cardiac arrhythmia resulting in increased risk of stroke. Despite highly heritable etiology, our understanding of the genetic architecture of AF remains incomplete. Here we performed a genome-wide association study in the Japanese population comprising 9,826 cases among 150,272 individuals and identified East Asian-specific rare variants associated with AF. A cross-ancestry meta-analysis of >1 million individuals, including 77,690 cases, identified 35 new susceptibility loci. Transcriptome-wide association analysis identified IL6R as a putative causal gene, suggesting the involvement of immune responses. Integrative analysis with ChIP-seq data and functional assessment using human induced pluripotent stem cell-derived cardiomyocytes demonstrated ERRg as having a key role in the transcriptional regulation of AF-associated genes. A polygenic risk score derived from the cross-ancestry meta-analysis predicted increased risks of cardiovascular and stroke mortalities and segregated individuals with cardioembolic stroke in undiagnosed AF patients. Our results provide new biological and clinical insights into AF genetics and suggest their potential for clinical applications.\n",
      "\n",
      "Category: Atrial Fibrillation\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style='color: cyan'>Output token 1:</span> A, <span style='color: darkorange'>logprobs:</span> -4.2391708e-05, <span style='color: magenta'>linear probability:</span> 100.0%<br><span style='color: cyan'>Output token 2:</span> Cong, <span style='color: darkorange'>logprobs:</span> -10.588518, <span style='color: magenta'>linear probability:</span> 0.0%<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Article Abstract: Pharmacologic clinical trials for heart failure with preserved ejection fraction have been largely unsuccessful as compared to those for heart failure with reduced ejection fraction. Whether differences in the genetic underpinnings of these major heart failure subtypes may provide insights into the disparate outcomes of clinical trials remains unknown. We utilize a large, uniformly phenotyped, single cohort of heart failure sub-classified into heart failure with reduced and with preserved ejection fractions based on current clinical definitions, to conduct detailed genetic analyses of the two heart failure sub-types. We find different genetic architectures and distinct genetic association profiles between heart failure with reduced and with preserved ejection fraction suggesting differences in underlying pathobiology. The modest genetic discovery for heart failure with preserved ejection fraction (one locus) compared to heart failure with reduced ejection fraction (13 loci) despite comparable sample sizes indicates that clinically defined heart failure with preserved ejection fraction likely represents the amalgamation of several, distinct pathobiological entities. Development of consensus sub-phenotyping of heart failure with preserved ejection fraction is paramount to better dissect the underlying genetic signals and contributors to this highly prevalent condition.\n",
      "\n",
      "Category: Congestive Heart Failure\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style='color: cyan'>Output token 1:</span> Cong, <span style='color: darkorange'>logprobs:</span> -0.0016410232, <span style='color: magenta'>linear probability:</span> 99.84%<br><span style='color: cyan'>Output token 2:</span> Card, <span style='color: darkorange'>logprobs:</span> -7.088118, <span style='color: magenta'>linear probability:</span> 0.08%<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for article in abstracts:\n",
    "    print(f\"Article Abstract: {article}\\n\")\n",
    "    API_RESPONSE = get_completion(\n",
    "        [{\"role\": \"user\", \"content\": CLASSIFICATION_PROMPT.format(headline=article)}],\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        logprobs=True,\n",
    "        top_logprobs=2,\n",
    "    )\n",
    "    top_two_logprobs = API_RESPONSE.choices[0].logprobs.content[0].top_logprobs\n",
    "    print(f\"Category: {API_RESPONSE.choices[0].message.content}\\n\")\n",
    "    html_content = \"\"\n",
    "    for i, logprob in enumerate(top_two_logprobs, start=1):\n",
    "        html_content += (\n",
    "            f\"<span style='color: cyan'>Output token {i}:</span> {logprob.token}, \"\n",
    "            f\"<span style='color: darkorange'>logprobs:</span> {logprob.logprob}, \"\n",
    "            f\"<span style='color: magenta'>linear probability:</span> {np.round(np.exp(logprob.logprob)*100,2)}%<br>\"\n",
    "        )\n",
    "    display(HTML(html_content))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This shows how important using `logprobs` can be, as if we are using LLMs for classification tasks we can set confidence theshholds, or output several potential output tokens if the log probability of the selected output is not sufficiently high. For instance, if we are creating a recommendation engine to tag articles and abstracts, we can automatically classify abstracts crossing a certain threshold, and send the less certain headlines for manual review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieval confidence scoring to reduce hallucinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce hallucinations, and the performance of our RAG-based Q&A system, we can use `logprobs` to evaluate how confident the model is in its retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we have built a retrieval system using RAG for Q&A, but are struggling with hallucinated answers to our questions. *Note:* we will use a hardcoded article for this example, but see other entries in the cookbook for tutorials on using RAG for Q&A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Article retrieved\n",
    "priest_results = \"\"\"Meta-analysis  identified  16  novel  loci,  including  12  rare  variants, \n",
    "which  displayed  moderate  or  large  effect  sizes  (median  odds  ratio,  3.02)  \n",
    "for  4  separate  CHD  categories.  Analyses  of  chromatin  structure  link  13  \n",
    "of  the  genome-wide significant  loci  to  key  genes  in  cardiac  development; \n",
    "rs373447426  (minor  allele  frequency,  0.003  [odds  ratio,  3.37  for  Conotruncal heart disease]; P=1.49×10−8) \n",
    "is predicted to disrupt chromatin structure for 2 nearby genes BDH1 and DLG1 involved  in  Conotruncal  development.\n",
    "A  lead  variant  rs189203952  (minor  allele  frequency,  0.01  [odds  ratio,  2.4  for  left ventricular outflow tract obstruction]; P=1.46×10−8) \n",
    "is predicted to disrupt the binding sites of 4 transcription factors known to participate in cardiac development in the promoter of SPAG9. \n",
    "A tissue-specific model of chromatin conformation suggests that common variant rs78256848 (minor allele frequency, 0.11 [odds ratio, 1.4 for Conotruncal heart disease]; P=2.6×10−8) \n",
    "physically interacts with NCAM1 (PFDR=1.86×10−27), a neural adhesion molecule acting in cardiac development. Importantly, while each individual \n",
    "malformation displayed substantial heritability (observed h2 ranging from 0.26 for complex malformations to 0.37 for left ventricular outflow tract obstructive disease) \n",
    "the risk for different CHD malformations appeared to be separate, without genetic correlation measured by linkage disequilibrium score regression or regional colocalization.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Questions that can be easily answered given the article\n",
    "easy_questions = [\n",
    "    \"How many rare variants were identified?\",\n",
    "    \"How many separate CHD categories were included in the meta-analysis?\"\n",
    "]\n",
    "\n",
    "# Questions that are not fully covered in the article\n",
    "medium_questions = [\n",
    "    \"What did the tissue-specific model of chromatin conformation suggest? Name the common variant identifier and gene name that is in physical content.\",\n",
    "    \"Why does the risk for different CHD malformations appear to be separate?\",\n",
    "    \"What genomic data and sequencing technology was used in the tissue specific model of chromatin conformation?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what we can do is ask the model to respond to the question, but then also evaluate its response. Specifically, we will ask the model to output a boolean `has_sufficient_context_for_answer`. We can then evaluate the `logprobs` to see just how confident the model is that its answer was contained in the provided context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"You retrieved this article: {article}. The question is: {question}.\n",
    "Before even answering the question, consider whether you have sufficient information in the article to answer the question fully.\n",
    "Your output should JUST be the boolean true or false, of if you have sufficient information in the article to answer the question.\n",
    "Respond with just one word, the boolean true or false. You must output the word 'True', or the word 'False', nothing else.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='True', bytes=[84, 114, 117, 101], logprob=-0.1508361, top_logprobs=[])])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Questions clearly answered in article<p style=\"color:green\">Question: How many rare variants were identified?</p><p style=\"color:cyan\">has_sufficient_context_for_answer: True, <span style=\"color:darkorange\">logprobs: -0.1508361, <span style=\"color:magenta\">linear probability: 86.0%</span></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "html_output = \"\"\n",
    "html_output += \"Questions clearly answered in article\"\n",
    "\n",
    "for question in easy_questions:\n",
    "    API_RESPONSE = get_completion(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": PROMPT.format(\n",
    "                    article=priest_results, question=question\n",
    "                ),\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        logprobs=True,\n",
    "    )\n",
    "    html_output += f'<p style=\"color:green\">Question: {question}</p>'\n",
    "    print(API_RESPONSE.choices[0].logprobs)\n",
    "    for logprob in API_RESPONSE.choices[0].logprobs.content:\n",
    "        html_output += f'<p style=\"color:cyan\">has_sufficient_context_for_answer: {logprob.token}, <span style=\"color:darkorange\">logprobs: {logprob.logprob}, <span style=\"color:magenta\">linear probability: {np.round(np.exp(logprob.logprob)*100,2)}%</span></p>'\n",
    "    break\n",
    "\n",
    "# html_output += \"Questions only partially covered in the article\"\n",
    "\n",
    "# for question in medium_questions:\n",
    "#     API_RESPONSE = get_completion(\n",
    "#         [\n",
    "#             {\n",
    "#                 \"role\": \"user\",\n",
    "#                 \"content\": PROMPT.format(\n",
    "#                     article=priest_results, question=question\n",
    "#                 ),\n",
    "#             }\n",
    "#         ],\n",
    "#         model=\"gpt-3.5-turbo\",\n",
    "#         logprobs=True,\n",
    "#         top_logprobs=3,\n",
    "#     )\n",
    "#     html_output += f'<p style=\"color:green\">Question: {question}</p>'\n",
    "#     for logprob in API_RESPONSE.choices[0].logprobs.content:\n",
    "#         html_output += f'<p style=\"color:cyan\">has_sufficient_context_for_answer: {logprob.token}, <span style=\"color:darkorange\">logprobs: {logprob.logprob}, <span style=\"color:magenta\">linear probability: {np.round(np.exp(logprob.logprob)*100,2)}%</span></p>'\n",
    "\n",
    "display(HTML(html_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first two questions, our model asserts with (near) 100% confidence that the article has sufficient context to answer the posed questions.<br><br>\n",
    "On the other hand, for the more tricky questions which are less clearly answered in the article, the model is less confident that it has sufficient context. This is a great guardrail to help ensure our retrieved content is sufficient.<br><br>\n",
    "This self-evaluation can help reduce hallucinations, as you can restrict answers or re-prompt the user when your `sufficient_context_for_answer` log probability is below a certain threshold. Methods like this have been shown to significantly reduce RAG for Q&A hallucinations and errors ([Example]((https://jfan001.medium.com/how-we-cut-the-rate-of-gpt-hallucinations-from-20-to-less-than-2-f3bfcc10e4ec)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Autocomplete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another use case for `logprobs` are autocomplete systems. Without creating the entire autocomplete system end-to-end, let's demonstrate how `logprobs` could help us decide how to suggest words as a user is typing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's come up with a sample sentence: `\"A variant disrupts transcription factors in cardiac development.\"` Let's say we want it to dynamically recommend the next word or token as we are typing the sentence, but *only* if the model is quite sure of what the next word will be. To demonstrate this, let's break up the sentence into sequential components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list = [\n",
    "\n",
    "    # A  lead  variant  rs189203952 is predicted to disrupt the binding sites of\n",
    "    # 4 transcription factors known to participate in cardiac development in the promoter of SPAG9. \n",
    "    \"A\",\n",
    "    \"A variant\",\n",
    "    \"A variant disrupts\",\n",
    "    \"A variant disrupts transcription\",\n",
    "    \"A variant disrupts transcription factors\",\n",
    "    \"A variant disrupts transcription factors in\",\n",
    "    \"A variant disrupts transcription factors in cardiac\",\n",
    "    \"A variant disrupts transcription factors in cardiac development\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can ask `gpt-3.5-turbo` to act as an autocomplete engine with whatever context the model is given. We can enable `logprobs` and can see how confident the model is in its prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Sentence: A</p><p style=\"color:cyan\">Predicted next token: dog, <span style=\"color:darkorange\">logprobs: -1.7934437, <span style=\"color:magenta\">linear probability: 16.64%</span></p><p style=\"color:cyan\">Predicted next token: cat, <span style=\"color:darkorange\">logprobs: -2.1530113, <span style=\"color:magenta\">linear probability: 11.61%</span></p><p style=\"color:cyan\">Predicted next token: bird, <span style=\"color:darkorange\">logprobs: -2.2873535, <span style=\"color:magenta\">linear probability: 10.15%</span></p><br><p>Sentence: A variant</p><p style=\"color:cyan\">Predicted next token: of, <span style=\"color:darkorange\">logprobs: -0.01621349, <span style=\"color:magenta\">linear probability: 98.39%</span></p><p style=\"color:cyan\">Predicted next token: A, <span style=\"color:darkorange\">logprobs: -4.258519, <span style=\"color:magenta\">linear probability: 1.41%</span></p><p style=\"color:cyan\">Predicted next token: is, <span style=\"color:darkorange\">logprobs: -6.463073, <span style=\"color:magenta\">linear probability: 0.16%</span></p><br><p>Sentence: A variant disrupts</p><p style=\"color:cyan\">Predicted next token: the, <span style=\"color:darkorange\">logprobs: -0.07296595, <span style=\"color:magenta\">linear probability: 92.96%</span></p><p style=\"color:cyan\">Predicted next token: normal, <span style=\"color:darkorange\">logprobs: -3.9747622, <span style=\"color:magenta\">linear probability: 1.88%</span></p><p style=\"color:cyan\">Predicted next token: global, <span style=\"color:darkorange\">logprobs: -4.1423535, <span style=\"color:magenta\">linear probability: 1.59%</span></p><br><p>Sentence: A variant disrupts transcription</p><p style=\"color:cyan\">Predicted next token: by, <span style=\"color:darkorange\">logprobs: -0.41872978, <span style=\"color:magenta\">linear probability: 65.79%</span></p><p style=\"color:cyan\">Predicted next token: and, <span style=\"color:darkorange\">logprobs: -1.3794708, <span style=\"color:magenta\">linear probability: 25.17%</span></p><p style=\"color:cyan\">Predicted next token: in, <span style=\"color:darkorange\">logprobs: -3.2380924, <span style=\"color:magenta\">linear probability: 3.92%</span></p><br><p>Sentence: A variant disrupts transcription factors</p><p style=\"color:cyan\">Predicted next token: and, <span style=\"color:darkorange\">logprobs: -0.85842913, <span style=\"color:magenta\">linear probability: 42.38%</span></p><p style=\"color:cyan\">Predicted next token: ,, <span style=\"color:darkorange\">logprobs: -1.5266612, <span style=\"color:magenta\">linear probability: 21.73%</span></p><p style=\"color:cyan\">Predicted next token: that, <span style=\"color:darkorange\">logprobs: -2.5219996, <span style=\"color:magenta\">linear probability: 8.03%</span></p><br><p>Sentence: A variant disrupts transcription factors in</p><p style=\"color:cyan\">Predicted next token: the, <span style=\"color:darkorange\">logprobs: -0.22892231, <span style=\"color:magenta\">linear probability: 79.54%</span></p><p style=\"color:cyan\">Predicted next token: a, <span style=\"color:darkorange\">logprobs: -2.3438897, <span style=\"color:magenta\">linear probability: 9.6%</span></p><p style=\"color:cyan\">Predicted next token: c, <span style=\"color:darkorange\">logprobs: -2.9487062, <span style=\"color:magenta\">linear probability: 5.24%</span></p><br><p>Sentence: A variant disrupts transcription factors in cardiac</p><p style=\"color:cyan\">Predicted next token: development, <span style=\"color:darkorange\">logprobs: -0.2117999, <span style=\"color:magenta\">linear probability: 80.91%</span></p><p style=\"color:cyan\">Predicted next token: mus, <span style=\"color:darkorange\">logprobs: -2.6636088, <span style=\"color:magenta\">linear probability: 6.97%</span></p><p style=\"color:cyan\">Predicted next token: cells, <span style=\"color:darkorange\">logprobs: -2.988272, <span style=\"color:magenta\">linear probability: 5.04%</span></p><br><p>Sentence: A variant disrupts transcription factors in cardiac development</p><p style=\"color:cyan\">Predicted next token: leading, <span style=\"color:darkorange\">logprobs: -0.3434278, <span style=\"color:magenta\">linear probability: 70.93%</span></p><p style=\"color:cyan\">Predicted next token: ,, <span style=\"color:darkorange\">logprobs: -1.8806344, <span style=\"color:magenta\">linear probability: 15.25%</span></p><p style=\"color:cyan\">Predicted next token: and, <span style=\"color:darkorange\">logprobs: -2.5327685, <span style=\"color:magenta\">linear probability: 7.94%</span></p><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "high_prob_completions = {}\n",
    "low_prob_completions = {}\n",
    "html_output = \"\"\n",
    "\n",
    "for sentence in sentence_list:\n",
    "    PROMPT = \"\"\"Complete this sentence. You are acting as auto-complete. Simply complete the sentence to the best of your ability, make sure it is just ONE sentence: {sentence}\"\"\"\n",
    "    API_RESPONSE = get_completion(\n",
    "        [{\"role\": \"user\", \"content\": PROMPT.format(sentence=sentence)}],\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        logprobs=True,\n",
    "        top_logprobs=3,\n",
    "    )\n",
    "    html_output += f'<p>Sentence: {sentence}</p>'\n",
    "    first_token = True\n",
    "    for token in API_RESPONSE.choices[0].logprobs.content[0].top_logprobs:\n",
    "        html_output += f'<p style=\"color:cyan\">Predicted next token: {token.token}, <span style=\"color:darkorange\">logprobs: {token.logprob}, <span style=\"color:magenta\">linear probability: {np.round(np.exp(token.logprob)*100,2)}%</span></p>'\n",
    "        if first_token:\n",
    "            if np.exp(token.logprob) > 0.95:\n",
    "                high_prob_completions[sentence] = token.token\n",
    "            if np.exp(token.logprob) < 0.60:\n",
    "                low_prob_completions[sentence] = token.token\n",
    "        first_token = False\n",
    "    html_output += \"<br>\"\n",
    "\n",
    "display(HTML(html_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the high confidence autocompletions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A variant': 'of'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_prob_completions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These look reasonable! We can feel confident in those suggestions. It's pretty likely you want to write 'of' after writing 'A variant of'(i.e., unknown signficance)! Now let's look at the autocompletion suggestions the model was less confident about:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 'dog', 'A variant disrupts transcription factors': 'and'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_prob_completions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are logical as well. It's pretty unclear what the user is going to say with just the prefix 'A', and it's really anyone's guess what or how the variant disrupts transcription factors. <br><br>\n",
    "So, using `gpt-3.5-turbo`, we can create the root of a dynamic autocompletion engine with `logprobs`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Highlighter and bytes parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly touch on creating a simple token highlighter with `logprobs`, and using the bytes parameter. First, we can create a function that counts and highlights each token. While this doesn't use the log probabilities, it uses the built in tokenization that comes with enabling `logprobs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"What's the longest gene name according to the HUGO gene name nomenclature?\"\"\"\n",
    "\n",
    "API_RESPONSE = get_completion(\n",
    "    [{\"role\": \"user\", \"content\": PROMPT}], model=\"gpt-3.5-turbo\", logprobs=True, top_logprobs=5\n",
    ")\n",
    "\n",
    "\n",
    "def highlight_text(api_response):\n",
    "    colors = [\n",
    "        \"#FF00FF\",  # Magenta\n",
    "        \"#008000\",  # Green\n",
    "        \"#FF8C00\",  # Dark Orange\n",
    "        \"#FF0000\",  # Red\n",
    "        \"#0000FF\",  # Blue\n",
    "    ]\n",
    "    tokens = api_response.choices[0].logprobs.content\n",
    "\n",
    "    color_idx = 0  # Initialize color index\n",
    "    html_output = \"\"  # Initialize HTML output\n",
    "    for t in tokens:\n",
    "        token_str = bytes(t.bytes).decode(\"utf-8\")  # Decode bytes to string\n",
    "\n",
    "        # Add colored token to HTML output\n",
    "        html_output += f\"<span style='color: {colors[color_idx]}'>{token_str}</span>\"\n",
    "\n",
    "        # Move to the next color\n",
    "        color_idx = (color_idx + 1) % len(colors)\n",
    "    display(HTML(html_output))  # Display HTML output\n",
    "    print(f\"Total number of tokens: {len(tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style='color: #FF00FF'>The</span><span style='color: #008000'> longest</span><span style='color: #FF8C00'> gene</span><span style='color: #FF0000'> name</span><span style='color: #0000FF'> according</span><span style='color: #FF00FF'> to</span><span style='color: #008000'> the</span><span style='color: #FF8C00'> H</span><span style='color: #FF0000'>UG</span><span style='color: #0000FF'>O</span><span style='color: #FF00FF'> gene</span><span style='color: #008000'> name</span><span style='color: #FF8C00'> n</span><span style='color: #FF0000'>omencl</span><span style='color: #0000FF'>ature</span><span style='color: #FF00FF'> is</span><span style='color: #008000'> \"</span><span style='color: #FF8C00'>meth</span><span style='color: #FF0000'>ion</span><span style='color: #0000FF'>yl</span><span style='color: #FF00FF'>-t</span><span style='color: #008000'>RNA</span><span style='color: #FF8C00'> synth</span><span style='color: #FF0000'>et</span><span style='color: #0000FF'>ase</span><span style='color: #FF00FF'> </span><span style='color: #008000'>2</span><span style='color: #FF8C00'>,</span><span style='color: #FF0000'> mitochondrial</span><span style='color: #0000FF'>\"</span><span style='color: #FF00FF'> which</span><span style='color: #008000'> is</span><span style='color: #FF8C00'> also</span><span style='color: #FF0000'> known</span><span style='color: #0000FF'> as</span><span style='color: #FF00FF'> \"</span><span style='color: #008000'>M</span><span style='color: #FF8C00'>ARS</span><span style='color: #FF0000'>2</span><span style='color: #0000FF'>\".</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens: 40\n"
     ]
    }
   ],
   "source": [
    "highlight_text(API_RESPONSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's reconstruct a sentence using the bytes parameter. With `logprobs` enabled, we are given both each token and the ASCII (decimal utf-8) values of the token string. These ASCII values can be helpful when handling tokens of or containing emojis or special characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: \\xf0\\x9f\n",
      "Log prob: -0.48728606\n",
      "Linear prob: 61.43 %\n",
      "Bytes: [240, 159] \n",
      "\n",
      "Token: \\xa7\n",
      "Log prob: -0.009539441\n",
      "Linear prob: 99.05 %\n",
      "Bytes: [167] \n",
      "\n",
      "Token: \\xac\n",
      "Log prob: -5.1331983e-05\n",
      "Linear prob: 99.99 %\n",
      "Bytes: [172] \n",
      "\n",
      "Token:  DNA\n",
      "Log prob: -0.8761488\n",
      "Linear prob: 41.64 %\n",
      "Bytes: [32, 68, 78, 65] \n",
      "\n",
      "Token:  Double\n",
      "Log prob: -1.1560525\n",
      "Linear prob: 31.47 %\n",
      "Bytes: [32, 68, 111, 117, 98, 108, 101] \n",
      "\n",
      "Token:  Hel\n",
      "Log prob: -4.3941356e-05\n",
      "Linear prob: 100.0 %\n",
      "Bytes: [32, 72, 101, 108] \n",
      "\n",
      "Token: ix\n",
      "Log prob: -6.704273e-07\n",
      "Linear prob: 100.0 %\n",
      "Bytes: [105, 120] \n",
      "\n",
      "Bytes array: [240, 159, 167, 172, 32, 68, 78, 65, 32, 68, 111, 117, 98, 108, 101, 32, 72, 101, 108, 105, 120]\n",
      "Decoded bytes: 🧬 DNA Double Helix\n",
      "Joint prob: 7.97 %\n"
     ]
    }
   ],
   "source": [
    "PROMPT = \"\"\"Output the genetics emoji and its name.\"\"\"\n",
    "API_RESPONSE = get_completion(\n",
    "    [{\"role\": \"user\", \"content\": PROMPT}], model=\"gpt-3.5-turbo\", logprobs=True\n",
    ")\n",
    "\n",
    "aggregated_bytes = []\n",
    "joint_logprob = 0.0\n",
    "\n",
    "# Iterate over tokens, aggregate bytes and calculate joint logprob\n",
    "for token in API_RESPONSE.choices[0].logprobs.content:\n",
    "    print(\"Token:\", token.token)\n",
    "    print(\"Log prob:\", token.logprob)\n",
    "    print(\"Linear prob:\", np.round(exp(token.logprob) * 100, 2), \"%\")\n",
    "    print(\"Bytes:\", token.bytes, \"\\n\")\n",
    "    aggregated_bytes += token.bytes\n",
    "    joint_logprob += token.logprob\n",
    "\n",
    "# Decode the aggregated bytes to text\n",
    "aggregated_text = bytes(aggregated_bytes).decode(\"utf-8\")\n",
    "\n",
    "# Assert that the decoded text is the same as the message content\n",
    "assert API_RESPONSE.choices[0].message.content == aggregated_text\n",
    "\n",
    "# Print the results\n",
    "print(\"Bytes array:\", aggregated_bytes)\n",
    "print(f\"Decoded bytes: {aggregated_text}\")\n",
    "print(\"Joint prob:\", np.round(exp(joint_logprob) * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see that while the first token was ` \\xf0\\x9f`, we can get its ASCII value and append it to a bytes array. Then, we can easily decode this array into a full sentence, and validate with our assert statement that the decoded bytes is the same as our completion message!\n",
    "\n",
    "Additionally, we can get the joint probability of the entire completion, which is the exponentiated product of each token's log probability. This gives us how `likely` this given completion is given the prompt. Since, our prompt is quite directive (asking for a certain emoji and its name), the joint probability of this output is high! If we ask for a random output however, we'll see a much lower joint probability. This can also be a good tactic for developers during prompt engineering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! We were able to use the `logprobs` parameter to build a more robust classifier, evaluate our retrieval for Q&A system, and encode and decode each 'byte' of our tokens! `logprobs` adds useful information and signal to our completions output, and we are excited to see how developers incorporate it to improve applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Possible extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many other use cases for `logprobs` that are not covered in this cookbook. We can use `logprobs` for:\n",
    "  - Evaluations (e.g.: calculate `perplexity` of outputs, which is the evaluation metric of uncertainty or surprise of the model at its outcomes)\n",
    "  - Moderation\n",
    "  - Keyword selection\n",
    "  - Improve prompts and interpretability of outputs\n",
    "  - Token healing\n",
    "  - and more!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
